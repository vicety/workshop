data: './data/data/save_data'
log: './data/data/log/'
epoch: 50
batch_size: 64
param_init: 0.1
optim: 'adam'
learning_rate: 0.001
max_grad_norm: 10
learning_rate_decay: 0.5
global_emb: False
mask: True
schedule: True
bidirec: True
start_decay_at: 5
score: 'hubness'
N: 1
margin: 0.3
view_score: False
emb_file: './data/data/weight_matrix_test'
emb_size: 300
encoder_hidden_size: 128
decoder_hidden_size: 256
num_layers: 2
dropout: 0.5
max_tgt_len: 8
eval_interval: 1
save_interval: 400
max_generator_batches: 32
metric: ['hamming_loss', 'micro_f1']
GRL_fraction: 1
softmax_linear_lr_mul: 0.0015
shared_vocab: False
beam_size: 1
k_max: 0
cheat: 0.1
