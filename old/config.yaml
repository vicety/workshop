data: './data/data/save_data'
log: './data/data/log/'
epoch: 50
batch_size: 64
param_init: 0.1
optim: 'adam'
learning_rate: 0.001
max_grad_norm: 10
learning_rate_decay: 0.5
global_emb: False
mask: True
schedule: True
bidirec: True
start_decay_at: 5
score: 'hybrid'
freeze: True
N: 5
err_mul: 0.2
margin: 0.4
novel: False
view_score: False
emb_file: './data/data/weight_matrix_train'
emb_size: 300
encoder_hidden_size: 256
decoder_hidden_size: 512
num_layers: 1
dropout: 0.5
max_tgt_len: 8
eval_interval: 500
save_interval: 500
max_generator_batches: 32
metric: ['hamming_loss', 'micro_f1']
shared_vocab: False
beam_size: 1
GRL_fraction: 0
softmax_linear_lr_mul: 0.0025
k_max: 2
cheat: 0
